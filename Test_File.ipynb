{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from artifacts.ai_pc import main_proc_change\n",
    "from config.params import ProcChangeConfig\n",
    "import csv\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AAM_MEXICO_DATA_ACCELERATION_EMA2252M10022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['READ_TIME'] = pd.to_datetime(df['READ_TIME'])\n",
    "# batch_size = 8  \n",
    "# df['batch'] = (df['READ_TIME'] - df['READ_TIME'].iloc[0]).dt.total_seconds() // (batch_size * 3600)\n",
    "\n",
    "# grouped = df.groupby('batch')\n",
    "\n",
    "# batch_results = []\n",
    "# for _, group in grouped:\n",
    "#     batch_start_hour = group['READ_TIME'].iloc[0].strftime('%Y%m%d%H')  # Format startHour as needed\n",
    "    \n",
    "#     batch_fetch_result = {\n",
    "#         \"data\": {\n",
    "#             \"moldId\": int(group['ID'].unique()[0]),\n",
    "#             \"counterId\": str(group['COUNTER_ID'].unique()[0]),\n",
    "#             \"startHour\": batch_start_hour,\n",
    "#             \"contractedCycleTime\": 360,\n",
    "#             \"accelerations\": group['ACCELERATIONS'].tolist(),\n",
    "#             \"dataAccId\": group['ID'].tolist(),\n",
    "#             \"measurementDate\": group['MEASUREMENT_DATE'].astype(str).tolist(),\n",
    "#             \"procChanged\": [None] * len(group),\n",
    "#             \"similarityMetric\": [None] * len(group),\n",
    "#             \"similarityMetricHr\": [None] * len(group),\n",
    "#         }\n",
    "#     }\n",
    "#     batch_results.append(batch_fetch_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Batch Using MEASUREMENT_DATE(1)\n",
    "# Define a function to convert datetime string to desired format\n",
    "def convert_to_custom_format(datetime_str):\n",
    "    datetime_obj = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')\n",
    "    return datetime_obj.strftime('%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the Data in 8 hour Period Based as similar to what described in the fetching schema\n",
    "# Set the timestamp as the DataFrame index\n",
    "df['MEASUREMENT_DATE'] = pd.to_datetime(df['MEASUREMENT_DATE'],format ='%Y%m%d%H%M%S')\n",
    "df.set_index('MEASUREMENT_DATE',inplace=True)\n",
    "# filename = filePath.split(\"/\")[-1].split(\".\")[0]\n",
    "# id = filename\n",
    "# Resample the data on an hourly basis and store only the non-empty hourly frames in a list\n",
    "hourly_frames = []\n",
    "hourlyshotsLabel = []\n",
    "hourname = []\n",
    "for name, group in df.resample(\"H\"):\n",
    "    if not group.empty:\n",
    "        hourname.append(name)\n",
    "        hourly_frames.append(group)\n",
    "first_batch = hourly_frames[1:9]\n",
    "df_first_batch = pd.concat(first_batch)\n",
    "\n",
    "df.reset_index(drop = False,inplace=True)\n",
    "df_first_batch.reset_index(drop = False,inplace=True)\n",
    "\n",
    "df_first_batch['MEASUREMENT_DATE'] = df_first_batch['MEASUREMENT_DATE'].astype(str)\n",
    "df_first_batch\n",
    "# Apply the function to the entire column\n",
    "df_first_batch['MEASUREMENT_DATE'] = df_first_batch['MEASUREMENT_DATE'].apply(convert_to_custom_format)\n",
    "df = df_first_batch\n",
    "# print(df.head())\n",
    "# logger.info(\"DataFrame:\\n%s\", df)\n",
    "# Convert DataFrame to the \"fetchScheme Result\" format\n",
    "# fetch_scheme_result = df.to_dict(orient='records')\n",
    "\n",
    "# logger.info('fetchScheme Result : %s', fetch_scheme_result)\n",
    "# Print the result\n",
    "# print()\n",
    "# for row in fetch_scheme_result:\n",
    "#     # print(row)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Batch Using MEASUREMENT_DATE(3)\n",
    "try: \n",
    "    dummy_fetchResult = {\n",
    "        \"data\": {\n",
    "            \"moldId\": int(df['MOLD_ID'].unique()[0]),\n",
    "            \"counterId\": str(df['COUNTER_ID'].unique()[0]),\n",
    "            \"startHour\":str(df['MEASUREMENT_DATE'][0])[:-4], # Left side of the Inference Boundary\n",
    "            \"contractedCycleTime\": 360,\n",
    "            \"accelerations\": df['ACCELERATIONS'].tolist(),\n",
    "            \"dataAccId\": df['ID'].tolist(),\n",
    "            \"measurementDate\": df['MEASUREMENT_DATE'].tolist(),\n",
    "            \"procChanged\": [None] * len(df['ID'].tolist()),  # Example process change indicators\n",
    "            \"similarityMetric\": [None] * len(df['ID'].tolist()),\n",
    "            \"similarityMetricHr\": [None] * len(df['ID'].tolist()),\n",
    "        }\n",
    "    }\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    dummy_fetchResult = {\n",
    "    \"data\": {\n",
    "        \"moldId\": df['TERMINAL_ID'].unique()[0],\n",
    "        \"counterId\": str(df['COUNTER_ID'].unique()[0]),\n",
    "        \"startHour\":str(df['MEASUREMENT_DATE'][0])[:-4], # Left side of the Inference Boundary\n",
    "        \"contractedCycleTime\": 360,\n",
    "        \"accelerations\": df['ACCELERATIONS'].tolist(),\n",
    "        \"dataAccId\": df['ID'].tolist(),\n",
    "        \"measurementDate\": df['MEASUREMENT_DATE'].tolist(),\n",
    "        \"procChanged\": [None] * len(df['ID'].tolist()),  # Example process change indicators\n",
    "        \"similarityMetric\": [None] * len(df['ID'].tolist()),\n",
    "        \"similarityMetricHr\": [None] * len(df['ID'].tolist()),\n",
    "    }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(dummy_fetchResult)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from artifacts.utils import generate_hrs_template\n",
    "print('Batch Start Hour: ',str(df['MEASUREMENT_DATE'][0])[:-4])\n",
    "print(generate_hrs_template(\n",
    "    str(df['MEASUREMENT_DATE'][0])[:-4],\n",
    "    4,\n",
    "    2,\n",
    "))\n",
    "batch_start_hour=str(df['MEASUREMENT_DATE'][0])[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate no data available for any timestamp\n",
    "no_data_batch = pd.DataFrame(columns=df_first_batch.columns)\n",
    "# Now you can use this no_data_batch to generate dummy_fetchResult\n",
    "df = no_data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use irregular timestamps for the batch\n",
    "irregular_timestamps_batch = df_first_batch.copy()\n",
    "irregular_timestamps_batch = irregular_timestamps_batch.iloc[::2]  # Select every other timestamp\n",
    "# Now you can use this irregular_timestamps_batch to generate dummy_fetchResult\n",
    "df= irregular_timestamps_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate missing data for some timestamps\n",
    "partial_data_batch = df_first_batch.copy()\n",
    "partial_data_batch = partial_data_batch[~partial_data_batch['MEASUREMENT_DATE'].isin(['2023-04-26 16:00:00', '2023-04-26 18:00:00'])]\n",
    "# Now you can use this partial_data_batch to generate dummy_fetchResult\n",
    "df=partial_data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.params import ProcChangeConfig\n",
    "\n",
    "result=main_proc_change(dummy_fetchResult,\n",
    "                THRESHOLD_SIM_METRIC=ProcChangeConfig.THRESHOLD_SIM_METRIC,\n",
    "                N_PREV_RECS=ProcChangeConfig.N_PREV_RECS,\n",
    "                FIRST_SECTION_PROP=ProcChangeConfig.FIRST_SECTION_PROP,\n",
    "                BIN_WIDTH_FIRST_SECTION=ProcChangeConfig.BIN_WIDTH_FIRST_SECTION,\n",
    "                BIN_WIDTH_SECOND_SECTION=ProcChangeConfig.BIN_WIDTH_SECOND_SECTION,\n",
    "\n",
    "                )\n",
    "print(result)\n",
    "# Convert the result to a DataFrame\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df\n",
    "# # Save the DataFrame to a CSV file\n",
    "# result_df.to_csv('PCD_MAIN_PROCESS_CHANGE_MEASUREMENT_DATE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from artifacts.ai_pc import identify_process_change\n",
    "from artifacts.ai_pc import get_hourly_summary\n",
    "from artifacts.ai_pc import parse_individual_records\n",
    "records_all = parse_individual_records(\n",
    "        dummy_fetchResult,\n",
    "        FIRST_SECTION_PROP=ProcChangeConfig.FIRST_SECTION_PROP,\n",
    "        BIN_WIDTH_FIRST_SECTION=ProcChangeConfig.BIN_WIDTH_FIRST_SECTION,\n",
    "        BIN_WIDTH_SECOND_SECTION=ProcChangeConfig.BIN_WIDTH_SECOND_SECTION,\n",
    ")\n",
    "records_all\n",
    "\n",
    "# df=pd.DataFrame(records_all)\n",
    "# df\n",
    "\n",
    "# custom_width = 130\n",
    "# pd.set_option('display.max_colwidth', custom_width)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# df\n",
    "\n",
    "ach=get_hourly_summary(\n",
    "    batch_start_hour,\n",
    "    records_all,\n",
    ")\n",
    "ach\n",
    "\n",
    "# identify_process_change(\n",
    "#         ach,\n",
    "#         0.7,  \n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from artifacts.utils import generate_hrs_template\n",
    "print('Batch Start Hour: ',str(df['MEASUREMENT_DATE'][0])[:-4])\n",
    "print(generate_hrs_template(\n",
    "    str(df['MEASUREMENT_DATE'][0])[:-4],\n",
    "    4,\n",
    "    2,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_start_hour= str(df['MEASUREMENT_DATE'][0])[:-4]\n",
    "from artifacts.utils import subtract_hours\n",
    "print(subtract_hours(\n",
    "            start_time=batch_start_hour,\n",
    "            hrs_to_sub=2,\n",
    "            input_fmt=\"%Y%m%d%H\",\n",
    "            output_fmt=\"%Y%m%d%H\",\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from artifacts.ai_pc import get_hourly_summary\n",
    "get_hourly_summary(\n",
    "        batch_start_hour,\n",
    "        records_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Timestamp\n",
    "\n",
    "# Define the timestamps to keep\n",
    "timestamps_to_keep = [\n",
    "    Timestamp('2023-04-26 13:00:00'),\n",
    "    Timestamp('2023-04-26 14:00:00'),\n",
    "    Timestamp('2023-04-26 15:00:00'),\n",
    "    Timestamp('2023-04-26 16:00:00'),\n",
    "    Timestamp('2023-04-26 17:00:00'),\n",
    "    Timestamp('2023-04-26 18:00:00'),\n",
    "    Timestamp('2023-04-26 19:00:00'),\n",
    "    Timestamp('2023-04-26 20:00:00')\n",
    "]\n",
    "\n",
    "# Filter the data based on the desired timestamps\n",
    "filtered_data = [\n",
    "    {\n",
    "        \"accelerations\": a,\n",
    "        \"dataAccId\": da,\n",
    "        \"measurementDate\": md,\n",
    "        \"procChanged\": pc,\n",
    "        \"similarityMetric\": sm,\n",
    "        \"similarityMetricHr\": smh\n",
    "    }\n",
    "    for a, da, md, pc, sm, smh in zip(\n",
    "        dummy_fetchResult['data']['accelerations'],\n",
    "        dummy_fetchResult['data']['dataAccId'],\n",
    "        dummy_fetchResult['data']['measurementDate'],\n",
    "        dummy_fetchResult['data']['procChanged'],\n",
    "        dummy_fetchResult['data']['similarityMetric'],\n",
    "        dummy_fetchResult['data']['similarityMetricHr']\n",
    "    )\n",
    "    if md in timestamps_to_keep\n",
    "]\n",
    "\n",
    "# Create the filtered dictionary\n",
    "filtered_dummy_fetchResult = {\n",
    "    \"data\": {\n",
    "        \"moldId\": dummy_fetchResult['data']['moldId'],\n",
    "        \"counterId\": dummy_fetchResult['data']['counterId'],\n",
    "        \"startHour\": dummy_fetchResult['data']['startHour'],\n",
    "        \"contractedCycleTime\": dummy_fetchResult['data']['contractedCycleTime'],\n",
    "        \"accelerations\": [data['accelerations'] for data in filtered_data],\n",
    "        \"dataAccId\": [data['dataAccId'] for data in filtered_data],\n",
    "        \"measurementDate\": [data['measurementDate'] for data in filtered_data],\n",
    "        \"procChanged\": [data['procChanged'] for data in filtered_data],\n",
    "        \"similarityMetric\": [data['similarityMetric'] for data in filtered_data],\n",
    "        \"similarityMetricHr\": [data['similarityMetricHr'] for data in filtered_data],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Assign the filtered dictionary back to dummy_fetchResult\n",
    "dummy_fetchResult = filtered_dummy_fetchResult\n",
    "## ... (previous code)\n",
    "\n",
    "# Assign the filtered dictionary back to dummy_fetchResult\n",
    "# ... (previous code)\n",
    "\n",
    "# Print the filtered_dummy_fetchResult to check its content\n",
    "print(\"Filtered Dummy Fetch Result:\", filtered_dummy_fetchResult)\n",
    "\n",
    "# Extract measurementDate values as strings\n",
    "measurement_date = [str(ts) for ts in filtered_dummy_fetchResult['data']['measurementDate']]\n",
    "\n",
    "# Join the measurementDate strings into a single string\n",
    "measurement_date_str = \", \".join(measurement_date)\n",
    "\n",
    "# Print the concatenated measurement dates\n",
    "print(\"Measurement Dates:\", measurement_date_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from artifacts.utils import generate_hrs_template\n",
    "print('Batch Start Hour: ',str(df['MEASUREMENT_DATE'][0])[:-4])\n",
    "print(generate_hrs_template(\n",
    "    str(2023042614),\n",
    "    4,\n",
    "    2,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Loop through the dictionary and extract relevant information\n",
    "for key, value in ach.items():\n",
    "    data.append({\n",
    "        'Hour': value.hour,\n",
    "        'Exists': value.exists,\n",
    "        'SimilarityMetric': value.sim_metric_hr,\n",
    "        'ProcChanged': value.proc_changed,\n",
    "        'ToReturn': value.to_return,\n",
    "\n",
    "        # Add more attributes as needed\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepChain",
   "language": "python",
   "name": "deepchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
